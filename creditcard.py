# -*- coding: utf-8 -*-
"""creditcard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hD-8uwnVcmtwW60-hlSizT3NDiFbCZGI

**1. Data Understanding + Loading**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

from imblearn.over_sampling import SMOTE
import shap
import joblib

# Load dataset
df = pd.read_csv("creditcard.csv")

# Basic understanding
print(df.head())
print(df.info())
print(df.describe())

"""2.**Exploratory Data Analysis (EDA)**"""

# Target distribution
sns.countplot(x="Class", data=df)
plt.title("Fraud vs Non-Fraud Distribution")
plt.show()

# Percentage of fraud cases
fraud_ratio = df["Class"].value_counts(normalize=True)
print(fraud_ratio)

# Correlation heatmap (small sample for speed)
plt.figure(figsize=(10,6))
sns.heatmap(df.sample(5000).corr(), cmap="coolwarm")
plt.title("Feature Correlation Heatmap")
plt.show()

"""**3. Feature Engineering**"""

# Create interaction feature
df["Amount_Time_Interaction"] = df["Amount"] * df["Time"]

# Log transform Amount (reduce skewness)
df["Log_Amount"] = np.log1p(df["Amount"])

# Drop original Amount (optional)
df.drop("Amount", axis=1, inplace=True)

"""**4. Train-Test Split**"""

df.dropna(subset=['Class'], inplace=True)
X = df.drop("Class", axis=1)
y = df["Class"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

"""**5. Data Preprocessing**"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""**6. Handling Class Imbalance**"""

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)

X_train_res = X_train_res
y_train_res = y_train_res

"""**7. Model Training**"""

model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    n_jobs=-1,
    random_state=42
)

model.fit(X_train_res, y_train_res)

"""**8. Model Evaluation**"""

y_pred = model.predict(X_test_scaled)
y_prob = model.predict_proba(X_test_scaled)[:, 1]

print("Confusion Matrix\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report\n", classification_report(y_test, y_pred))
print("\nROC AUC Score:", roc_auc_score(y_test, y_prob))

"""**9. EXPLAINABLE AI USING SHAP**"""

# SHAP Explainer
explainer = shap.TreeExplainer(model)

X_sample = X_test_scaled[:1000]

shap_values = explainer.shap_values(X_sample)

feature_names = X.columns

# Summary plot for the positive class (class 1)
shap.summary_plot(
    shap_values[:, :, 1],
    X_sample,
    feature_names=feature_names
)

"""**10. Save Model**"""

joblib.dump(model, "fraud_model.pkl")
joblib.dump(scaler, "scaler.pkl")

